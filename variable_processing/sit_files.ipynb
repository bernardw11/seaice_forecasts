{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce61d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from cartopy import crs as ccrs, feature as cfeature\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import xarray as xr\n",
    "import glob, os\n",
    "#print(xr.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ec27e",
   "metadata": {},
   "source": [
    "## Just the exact same as the OHC files. B/c it's also ORAS5 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702342bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of monthly files: 521\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/d6/bxw2101/oras5_sit\")\n",
    "sit_1 = glob.glob(\"sit_firstgroup/iicethic_control*.nc\")\n",
    "sit_2 = glob.glob(\"sit_secondgroup/iicethic_control*.nc\")\n",
    "all_sit_files = sit_1 + sit_2\n",
    "all_sit_files.sort()\n",
    "print(\"# of monthly files: \" + str(len(all_sit_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c76980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_all = xr.open_mfdataset(all_sit_files, concat_dim='time_counter', combine='nested')\n",
    "# #this takes maybe 20-30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec49b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_crop = ds_all.where(ds_all.nav_lat < -50)\n",
    "# ds_crop.to_netcdf('all_sit_monthly.nc', mode='w',format='NETCDF4')\n",
    "# #this also took maybe 20-30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "993bdce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/d6/bxw2101/oras5_sit/all_sit_monthly.nc'\n",
    "ds = xr.open_dataset(filename, decode_times=False)\n",
    "\n",
    "date_1 = datetime.datetime.strptime(\"01/16/1979\", \"%m/%d/%Y\")\n",
    "def convert_times(x):\n",
    "  return (date_1 + relativedelta(hours=int(x))).replace(day=1, hour=0)\n",
    "convert_times_v = np.vectorize(convert_times)\n",
    "ds = ds.assign_coords(time_counter=convert_times_v(ds.time_counter))\n",
    "ds = ds.rename({'time_counter': 'tdim'})\n",
    "\n",
    "# Dataset notes:\n",
    "# y: indices 0 to 1021. x: indices 0 to 1441.\n",
    "# for nav_lat and nav_lon: it's in the format of (y, x). origin is bottom left.\n",
    "# longitude, AFAIK, roughly increases by 0.25 degrees each increment. roughly.\n",
    "# I have already cropped using .where() to just include latitudes < -50 degrees for the southern ocean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71ce442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Just plotting nav_lon and nav_lat. they are two-dimensional scalar fields. (obv)\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(14, 4))\n",
    "ds.nav_lon.plot(ax=ax1)\n",
    "ds.nav_lat.plot(ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81cd964",
   "metadata": {},
   "source": [
    "## Quick n dirty SIT and OHC comparison w the WHOLE coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca14782",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/d6/bxw2101/oras5_ohc/all_ohc_monthly.nc'\n",
    "ds_ohc = xr.open_dataset(filename, decode_times=False)\n",
    "\n",
    "date_1 = datetime.datetime.strptime(\"01/16/1978\", \"%m/%d/%Y\")\n",
    "def convert_times(x):\n",
    "  return (date_1 + relativedelta(hours=int(x))).replace(day=1)\n",
    "convert_times_v = np.vectorize(convert_times)\n",
    "ds_ohc = ds_ohc.assign_coords(time_counter=convert_times_v(ds_ohc.time_counter))\n",
    "ds_ohc = ds_ohc.rename({'time_counter': 'tdim'})\n",
    "ds_ohc = ds_ohc.drop_isel(tdim=list(range(12)))\n",
    "# Dataset notes:\n",
    "# y: indices 0 to 1021. x: indices 0 to 1441.\n",
    "# for nav_lat and nav_lon: it's in the format of (y, x). origin is bottom left.\n",
    "# longitude, AFAIK, roughly increases by 0.25 degrees each increment. roughly.\n",
    "# I have already cropped using .where() to just include latitudes < -50 degrees for the southern ocean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e235b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_ohc.sohtc300\n",
    "# ds.iicethic\n",
    "og_grid_corr = xr.corr(ds.iicethic, ds_ohc.sohtc300, dim='tdim') # takes some time\n",
    "#og_grid_corr.min()\n",
    "#og_grid_corr.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b08cd",
   "metadata": {},
   "source": [
    "### WOAH. here I am doing the correlation between SIT and OHC absolute values, not the anomalies. \n",
    "Should I be doing correlation btwn absolute values or correlations between ANOMALIES???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = ccrs.SouthPolarStereo()\n",
    "pc = ccrs.PlateCarree() # The OG Data is in pc projection.\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = plt.axes(projection=sp)\n",
    "og_grid_corr.plot.pcolormesh(\n",
    "    ax=ax, transform=pc, x=\"nav_lon\", y=\"nav_lat\", vmin = -1, vmax = .3, cmap='plasma' # This gon be the way we plot this stuff.\n",
    ")\n",
    "ax.coastlines()\n",
    "ax.set_extent([-3950000., 3950000., 4350000., -3950000.], crs=sp)\n",
    "plt.title(\"Correlation btwn SIT and OHC, using the original fine coordinates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c42044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just tryna see one single frame:\n",
    "\n",
    "arb_time = ds.iicethic.sel(tdim='2017-11-01')\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = plt.axes(projection=sp)\n",
    "arb_time[0].plot.pcolormesh(\n",
    "    ax=ax, transform=pc, x=\"nav_lon\", y=\"nav_lat\", # This gon be the way we plot this stuff.\n",
    ")\n",
    "ax.coastlines()\n",
    "ax.set_extent([-3950000., 3950000., 4350000., -3950000.], crs=sp)\n",
    "plt.title(\"Correlation btwn SIT and OHC, using the original fine coordinates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b67a1b6",
   "metadata": {},
   "source": [
    "## Tryna build a new SIT dataset that is 2x2 lon/lat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc5b8ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the new dataset takes a while. There are a bunch of lat/lon combinations to go through.\n",
    "# This code takes the NEAREST\n",
    "\n",
    "# tdim: 516, Y: 20, X: 180 IS OUR DIMENSIONS. (for 1979-01-01 to 2021-12-01)\n",
    "lat_bins = np.arange(-88., -49, 2)\n",
    "lon_bins = np.arange(0., 359, 2)\n",
    "building_data = np.empty([20, 180, 521])\n",
    "#y, x, tdim is our order of dimensions.\n",
    "\n",
    "for lat in lat_bins:\n",
    "    for lon in lon_bins:\n",
    "        # First, find the index of the grid point nearest a specific lat/lon.\n",
    "        \n",
    "        # convert 180 to 358 to -180 to -2.\n",
    "        if lon > 179:\n",
    "            lon = lon - 360\n",
    "        \n",
    "        abslat = np.abs(ds.nav_lat-lat)\n",
    "        abslon = np.abs(ds.nav_lon-lon)\n",
    "\n",
    "        c = abslon**2 +  abslat**2\n",
    "\n",
    "        (ypts, xpts) = np.where(c == np.min(c))\n",
    "        yloc = ypts[0]\n",
    "        xloc = xpts[0]\n",
    "\n",
    "        # Now I can use that index location to get the values at the x/y diminsion\n",
    "        point_ds = ds.isel(x=xloc, y=yloc)\n",
    "        point_ds = point_ds.assign_coords({\"y\": lat, \"x\": lon})\n",
    "        #print(point_ds)\n",
    "\n",
    "        yi = int((lat + 88) / 2)\n",
    "        xi = int(lon / 2)\n",
    "\n",
    "        building_data[yi][xi] = point_ds.iicethic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a6c2992",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = ds.tdim.values\n",
    "regridded_sit = xr.DataArray(building_data, coords=[lat_bins, lon_bins, times], dims=['y', 'x', 'tdim'])\n",
    "new_ds = xr.Dataset(data_vars = {\"sit\": regridded_sit})\n",
    "new_ds = new_ds.transpose(\"tdim\", \"y\", \"x\")\n",
    "new_ds.to_netcdf('/d6/bxw2101/combined_netcdf_files/new_sit_monthly_2x2.nc', mode='w',format='NETCDF4')\n",
    "# regridded_ohc here is the new!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f170ea1c",
   "metadata": {},
   "source": [
    "## doing stuff w the 2x2 latitude longitude grid. PLOT LIKE THE SST FILES. Calculating the anomaly here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec0bda85",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/d6/bxw2101/combined_netcdf_files/new_sit_monthly_2x2.nc'\n",
    "r_ds = xr.open_dataset(filename)\n",
    "r_sit = r_ds.sit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fdb57a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# NEW REGRIDDED SIT plot\n",
    "arb_time_regrid = r_sit.sel(tdim='2017-11-01')\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = plt.axes(projection=sp)\n",
    "arb_time_regrid.plot(transform=pc) #arb_time.plot(ax=ax,  vmin=0, vmax=1, cmap='coolwarm')\n",
    "ax.coastlines()\n",
    "ax.gridlines(draw_labels=True)\n",
    "ax.set_extent([-3950000., 3950000., 4350000., -3950000.], crs=sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f1f200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_clim_period = r_ds.sel(tdim=slice('1979-01-01', '2021-12-01'))\n",
    "r_clim_sit = r_clim_period.sit\n",
    "\n",
    "r_sit_mon = r_sit.groupby('tdim.month')\n",
    "r_sit_clim = r_clim_sit.groupby('tdim.month').mean(dim='tdim')\n",
    "r_sit_anom = r_sit_mon - r_sit_clim\n",
    "r_sit_anom = r_sit_anom.drop_vars('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "604f9e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sit_anom_ds = xr.Dataset(data_vars = {\"sit_anom\": r_sit_anom})\n",
    "sit_anom_ds = sit_anom_ds.sel(tdim=slice('1979-01-01', '2021-12-01'))\n",
    "sit_anom_ds.to_netcdf('/d6/bxw2101/combined_netcdf_files/sit_anom_monthly_2x2.nc', mode='w',format='NETCDF4')\n",
    "#YAY WE HAVE THE OHC ANOMALY."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
