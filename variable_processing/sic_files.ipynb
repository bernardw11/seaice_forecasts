{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "635ca2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import datetime\n",
    "\n",
    "from cartopy import crs as ccrs, feature as cfeature\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import xarray as xr\n",
    "import glob, os\n",
    "#print(xr.__version__)\n",
    "import xskillscore as xs\n",
    "\n",
    "import eofs\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sp = ccrs.SouthPolarStereo()\n",
    "pc = ccrs.PlateCarree()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa022c60",
   "metadata": {},
   "source": [
    "## Getting the original sea ice concentration dataset: originally from NSIDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb02b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/d6/bxw2101/seaice_conc_monthly/all_seaice_conc_monthly.nc'\n",
    "ds = xr.open_dataset(filename)\n",
    "ds = ds.rename(time='tdim')\n",
    "ds = ds.rename(xgrid='x')\n",
    "ds = ds.rename(ygrid='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d5fb7e",
   "metadata": {},
   "source": [
    "just so you know: there is stdev_of_cdf_seaice_conc_monthly variable that might be useful later!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83482e5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#We want to give each [x,y] combination a new lat and lon coordinate.\n",
    "#The latitude/longitude file\n",
    "filename = '/d6/bxw2101/seaice_conc_monthly/grid_files/NSIDC0771_LatLon_PS_S25km_v1.0.nc'\n",
    "psgds = xr.open_dataset(filename)\n",
    "ds = ds.assign_coords(nav_lat=psgds.latitude)\n",
    "ds = ds.assign_coords(nav_lon=psgds.longitude)\n",
    "sic_ds = ds\n",
    "# THIS IS THE SIC DATASET WE HAVE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to remove the x,y coordinates that have zero values or flagged values.\n",
    "# Practically, this would work by converting the 2d xy matrix to a 1d array of (x,y) pairs.\n",
    "# Then removing the (x,y) pairs whose entire rows of values = 0 or flag value.\n",
    "# THEN manually performing the eof analysis. however, it would be nice if there was a function to do that automatically.\n",
    "#ds_crop = ds.where((ds.cdr_seaice_conc_monthly>0) & (ds.cdr_seaice_conc_monthly < 2.51), 0, drop=True)\n",
    "#ds = ds_crop\n",
    "# nah this do not work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc451058",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/58758480/xarray-select-nearest-lat-lon-with-multi-dimension-coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04601c19",
   "metadata": {},
   "source": [
    "## Building the new SIC dataset: 1longx0.5lat grid cell. regridding the xy km grid to lat,lon dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e46ae43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the new dataset takes a while. There are a bunch of lat/lon combinations to go through.\n",
    "# This code takes the NEAREST\n",
    "\n",
    "# IF WE WERE TRYING TO MAKE A 2X2, LIKE FOR THE REST OF THE VARIABLES:\n",
    "# tdim: 516, Y: 20, X: 180\n",
    "# lat_bins = np.arange(-88., -49, 2)\n",
    "# lon_bins = np.arange(0., 359, 2)\n",
    "# building_data = np.empty([20, 180, 518])\n",
    "# y, x, tdim is our order of dimensions.\n",
    "\n",
    "# now, building a 1 degree longitude by 0.5 degree latitude:\n",
    "lat_bins = np.arange(-89.5, -49.5, 0.5) #Y: 80\n",
    "lon_bins = np.arange(0., 360, 1) # X: 360\n",
    "building_data = np.empty([80, 360, 518])\n",
    "# tdim: 516, Y: 80, X: 360. So it will be 8 times as large as the 2x2 grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb812e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lat in lat_bins:\n",
    "    for lon in lon_bins:\n",
    "        # First, find the index of the grid point nearest a specific lat/lon.\n",
    "        \n",
    "        # convert 180 to 358 to -180 to -2.\n",
    "        if lon > 179.9:\n",
    "            lon = lon - 360\n",
    "        \n",
    "        abslat = np.abs(ds.nav_lat-lat)\n",
    "        abslon = np.abs(ds.nav_lon-lon)\n",
    "\n",
    "        c = abslon**2 +  abslat**2\n",
    "\n",
    "        (ypts, xpts) = np.where(c == np.min(c))\n",
    "        yloc = ypts[0]\n",
    "        xloc = xpts[0]\n",
    "\n",
    "        # Now I can use that index location to get the values at the x/y diminsion\n",
    "        point_ds = ds.isel(x=xloc, y=yloc)\n",
    "        point_ds = point_ds.assign_coords({\"y\": lat, \"x\": lon})\n",
    "        point_ds\n",
    "\n",
    "        # Convert to indices of the building_data array.\n",
    "#         yi = int((lat + 88) / 2)\n",
    "#         xi = int(lon / 2) (these are for 2x2 grid.. we are now doing 1lonx0.5lat grid)\n",
    "\n",
    "        yi = int((lat + 89.5) * 2)\n",
    "        xi = int(lon)\n",
    "\n",
    "        building_data[yi][xi] = point_ds.cdr_seaice_conc_monthly.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50084d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = ds.tdim.values\n",
    "regridded_sic = xr.DataArray(building_data, coords=[lat_bins, lon_bins, times], dims=['y', 'x', 'tdim'])\n",
    "new_ds = xr.Dataset(data_vars = {\"sic\": regridded_sic})\n",
    "new_ds = new_ds.transpose(\"tdim\", \"y\", \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e28d88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds.to_netcdf('/d6/bxw2101/combined_netcdf_files/new_cdr_sic_monthly_1x0p5.nc', mode='w',format='NETCDF4')\n",
    "#new_ds.to_netcdf('/d6/bxw2101/combined_netcdf_files/new_cdr_sic_monthly_2x2.nc', mode='w',format='NETCDF4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f8fab",
   "metadata": {},
   "source": [
    "## Load the new 1longx0.5lat dataset SIC here (not anomaly yet, calculating the anomaly happens later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "209aa59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/d6/bxw2101/combined_netcdf_files/new_cdr_sic_monthly_1x0p5.nc'\n",
    "regrid_sic_ds = xr.open_dataset(filename)\n",
    "# we have: \n",
    "#  - regrid_sic_ds: the new regridded, 1x0.5 lon/lat axes grid.\n",
    "#        y: 80, x: 360, tdim: 518. 1978-11-01 to 2021-12-01\n",
    "#        if we want to do EOF analysis, we might want to remove all x,y coords with sic = 0 or >=251.\n",
    "#.       that would require us to convert to a 2d grid manually. turn the 3d \n",
    "#  - sic_ds: the OG x,y 25kmx25km grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbaca1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "regrid_sic_var = regrid_sic_ds.sic.where(regrid_sic_ds.sic<2.51)\n",
    "sic_var = ds.cdr_seaice_conc_monthly.where(ds.cdr_seaice_conc_monthly < 2.51)\n",
    "# nsidc_bt_seaice_conc_monthly is another option. but we will use cdr_seaice_conc_monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e02fe",
   "metadata": {},
   "source": [
    "regrid_sic_var goes from 1978-11-01 to 2021-12-01 and has nan's for all the flagged land values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe7ecb9",
   "metadata": {},
   "source": [
    "chop regrid_sic_var into 1979-2021 by taking out nov,dec of 1978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a47f8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chop_regrid_sic_var = regrid_sic_var.isel(tdim=slice(2, 518))\n",
    "sic_mon = chop_regrid_sic_var.groupby('tdim.month')\n",
    "sic_clim = sic_mon.mean(dim='tdim')\n",
    "clim_std = sic_mon.std(dim='tdim')\n",
    "regrid_sic_anom = sic_mon - sic_clim\n",
    "regrid_sic_anom = regrid_sic_anom.drop_vars('month')\n",
    "# regrid_sic_anom is the one.\n",
    "\n",
    "sic_anom_ds = xr.Dataset(data_vars = {\"sic_anom\": regrid_sic_anom})\n",
    "sic_anom_ds = sic_anom_ds.sel(tdim=slice('1979-01-01', '2021-12-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00aaca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sic_anom_ds.to_netcdf('/d6/bxw2101/combined_netcdf_files/sic_anom_monthly_1x0p5.nc', mode='w',format='NETCDF4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f717a8",
   "metadata": {},
   "source": [
    "## Saved the file to use in the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cddd1c",
   "metadata": {},
   "source": [
    "## Getting the 1979-2000 data, to emulate the 2004 paper: save to a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8809851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_chop_regrid_sic_var = regrid_sic_var.isel(tdim=slice(2, 266))\n",
    "o_sic_mon = o_chop_regrid_sic_var.groupby('tdim.month')\n",
    "o_sic_clim = o_sic_mon.mean(dim='tdim')\n",
    "o_clim_std = o_sic_mon.std(dim='tdim')\n",
    "o_regrid_sic_anom = o_sic_mon - o_sic_clim\n",
    "o_regrid_sic_anom = o_regrid_sic_anom.drop_vars('month')\n",
    "# regrid_sic_anom is the one.\n",
    "\n",
    "o_sic_anom_ds = xr.Dataset(data_vars = {\"sic_anom\": o_regrid_sic_anom})\n",
    "o_sic_anom_ds = o_sic_anom_ds.sel(tdim=slice('1979-01-01', '2021-12-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "984e2c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_sic_anom_ds.to_netcdf('/d6/bxw2101/o_combined_netcdf_files/o_sic_anom_monthly_1x0p5.nc', mode='w',format='NETCDF4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
