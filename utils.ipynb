{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a9f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given hcast or cross, and given a region:\n",
    "#  - slice up the observed anomaly dataset into 'sic_obsr': the correct time period and region. Validpoints.\n",
    "#  - direct our path to the hcast or cross folder, where we can get our zz matrices.\n",
    "def hcast_or_cross(matrix_type, region):\n",
    "    if matrix_type == 'hcast':\n",
    "        os.chdir(\"/d6/bxw2101/model_files/hcast_output\")\n",
    "        sic_obsr = sic_obs_h.where(region)\n",
    "    elif matrix_type == 'cross':\n",
    "        os.chdir(\"/d6/bxw2101/model_files/cross_output\")\n",
    "        sic_obsr = sic_obs_c.where(region)\n",
    "    else:\n",
    "        raise Exception('You dummy. first parameter needs be \\'hcast\\' or \\'cross\\'.'+\n",
    "                        '\\nSo we know what model we are comparing.')\n",
    "    return sic_obsr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0373a23e",
   "metadata": {},
   "source": [
    "### The basic Corr/RMSE plots creator function: given corr/rmse matrices, plot them pretty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ab1438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Function used to plot the corr and rmse matrices.\n",
    "def plot_corrs_rmses(flen, matrix_type, avg_corrs, avg_rmse, persistence_c, persistence_r, clegend = []):\n",
    "    #__Variables:\n",
    "    #  flen: length of the list of model file names\n",
    "    #  avg_corrs: correlation to leadtime array for each model file (to be plotted)\n",
    "    #  avg_rmse: rmse to leadtime array for each model file (to be plotted)\n",
    "    #  matrix_type: hcast or cross. \n",
    "    #NOPE: zz_files: the actual list of model file names\n",
    "    #  persistence_c: correlation persistence. (to be plotted)\n",
    "    #  persistence_r: rmse persistence. (to be plotted)\n",
    "    #  clegend: graph legend for display. just the list of model files.    \n",
    "    \n",
    "    # defining the graph's legend:\n",
    "    if len(clegend) == 0:\n",
    "        clegend = [zz_files[i].split('-')[0] for i in range(len(zz_files))]\n",
    "        \n",
    "    xticks = np.arange(1, 13)\n",
    "    \n",
    "    #building out the correlation plot: first graph the persistence correlation, then the model correlations.\n",
    "    fig = plt.figure(figsize=(14,10))\n",
    "    plt.suptitle('Correlation and RMSE compared to lead time: ' + matrix_type, fontsize=30)\n",
    "    plt.plot(xticks, persistence_c, linewidth = 3, color = 'k', linestyle='dashed')\n",
    "    for i in range(flen):\n",
    "        plt.plot(xticks, avg_corrs[i], linewidth=3)\n",
    "        \n",
    "    #format and name the correlation plot.\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.xticks(xticks, fontsize=20);\n",
    "    plt.ylabel('Correlation Coefficient', fontsize=30)\n",
    "    plt.xlabel('Lead Time (Months)', fontsize=30)\n",
    "    plt.legend(['persistence'] + clegend)#, prop={'size': 30})\n",
    "    plt.show()\n",
    "\n",
    "    #building out the rmse plot: first graph persistence rmse, then the model rmses.\n",
    "    fig = plt.figure(figsize=(14,10))\n",
    "    plt.plot(xticks, persistence_r*100, linewidth = 3, color = 'k', linestyle='dashed')\n",
    "    for i in range(flen):\n",
    "        plt.plot(xticks, avg_rmse[i]*100, linewidth = 3)\n",
    "        \n",
    "    #format and name the rmse plot.\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.xticks(xticks, fontsize=20)\n",
    "    plt.ylabel('RMS Error (%)', fontsize=30)\n",
    "    plt.xlabel('Lead Time (Months)', fontsize=30)\n",
    "    plt.legend(['persistence'] +  clegend)#, prop={'size': 30})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99dec6b",
   "metadata": {},
   "source": [
    "## defining a function that will plot the corr/rmse files you input, in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "884fa709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually enter the filenames as a list.\n",
    "# can return a lot of info, or nothing. u can change it.\n",
    "def leadtime_plot(matrix_type, zz_files, region, clegend = []):\n",
    "    # matrix_type: hcast or cross.\n",
    "    # zz_files: the list of zz file names. to plot\n",
    "    # region: where to calculate the correlation and rmse.\n",
    "    # clegend: graph legend for display.\n",
    "    \n",
    "    # Define the legend here: Just the file name. Includes: variables, weights, mode #.\n",
    "    if len(clegend) == 0:\n",
    "        clegend = zz_files\n",
    "        # the following does not include weights:\n",
    "        #clegend = [zz_files[i].split('-')[0] + '-' + zz_files[i].split('-')[-1] for i in range(len(zz_files))]\n",
    "        \n",
    "    # Calculate UNweighted mean of the observed region SIC anomaly. correct time period. only validpoints. smoothed.\n",
    "    sic_obsr = hcast_or_cross(matrix_type, region)\n",
    "    sic_obsr_mean = sic_obsr.mean(dim=['x','y'])\n",
    "    \n",
    "    # Calculate persistence of the observed anomalies\n",
    "    persistence_c = np.zeros(12)\n",
    "    persistence_r = np.zeros(12)\n",
    "    for lag in range(1,13):\n",
    "        persistence_c[lag-1] = xr.corr(sic_obsr_mean.shift(tdim=-lag), sic_obsr_mean, dim='tdim').data\n",
    "        persistence_r[lag-1] = xs.rmse(sic_obsr_mean.shift(tdim=-lag), sic_obsr_mean, dim='tdim', skipna=True).data\n",
    "    \n",
    "    # Now, for every zz file: calculate the correlation between observed and model anomalies.\n",
    "    flen = len(zz_files)\n",
    "    print(\"# of zz matrices to plot: \" + str(flen))\n",
    "\n",
    "    avg_corrs = np.zeros([flen, 12])\n",
    "    avg_rmse = np.zeros([flen, 12])\n",
    "    for i in range(flen):\n",
    "        # Load in the model file.\n",
    "        zz_name = zz_files[i]\n",
    "        print('Loaded in ' + zz_name)\n",
    "        \n",
    "        # Calculate UNweighted mean of the cross validation zz matrix' region.\n",
    "        sic_zz =xr.open_dataset(zz_name).__xarray_dataarray_variable__\n",
    "        sic_zzr = sic_zz.where(region).where(validpoints)\n",
    "        sic_zzr_mean = sic_zzr.mean(dim=['x','y'])\n",
    "        \n",
    "        # Calculate correlation and rmse btwn observed and model anomalies.\n",
    "        for lead in range(1, 13):\n",
    "            avg_corrs[i, lead-1] = xr.corr(sic_obsr_mean, sic_zzr_mean.sel(lead=lead), dim='tdim').data\n",
    "            avg_rmse[i, lead-1] = xs.rmse(sic_obsr_mean, sic_zzr_mean.sel(lead=lead), dim='tdim', skipna=True).mean().data\n",
    "             \n",
    "    # Toss the avg_corrs matrix and avg_rmse matrix into the plot_cors_rmses() function.    \n",
    "    plot_corrs_rmses(flen, matrix_type, avg_corrs, avg_rmse, persistence_c, persistence_r, clegend)\n",
    "    \n",
    "    # return a bunch of things, cuz why not.\n",
    "    #return flen, matrix_type, zz_files, region, avg_corrs, avg_rmse, persistence_c, persistence_r\n",
    "    return avg_corrs, avg_rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e8f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ayo(x):\n",
    "    print('we just testing to see if utils was imported properly.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e2590",
   "metadata": {},
   "source": [
    "# bruh eventually build the model to just take in 1979-2000 data tbh... like... recreate the ENTIRE THING.... it'll take so long but it might be worth it to figure out if ur model is running well or not. I think it's safe to assume the model is running well rn tho."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc229272",
   "metadata": {},
   "source": [
    "## Testing to try and recreate the 1979-2000 data:\n",
    "- in the future, when u run the model with the 1979-2000 data just to make sure our model works, create a new file. save the output as new file names. that will take a while. just so u know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a8fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Give the output a full file name in the format:\n",
    "# # variables_separated_by_underscores - weights*separated*by*astericks - #ofmodes\n",
    "# complete_fname = f_name+'-'+ str(modes) + '.nc'\n",
    "# print('Building hcast and cross for: '+ complete_fname)\n",
    "\n",
    "# # run the solver here.\n",
    "# solver = MultivariateEof(model_vars,\n",
    "#                      weights = model_wgts, center=False)\n",
    "# nvars = nv-1 # nvars: number of variables NOT sic. ex. sst, sat: nvars = 2. i=0, 1.\n",
    "\n",
    "# #____________________Solve for MEOFs, PCs\n",
    "# # define the lat, lon coordinates for the variables.\n",
    "# sic_lat_bins = np.arange(-89.5, -49.5, 0.5)\n",
    "# sic_lon_bins = np.arange(0., 360, 1)\n",
    "# vars_lat_bins = np.arange(-88., -49, 2)\n",
    "# vars_lon_bins = np.arange(0., 359, 2)\n",
    "\n",
    "# # get the eofs, pcs, eigenvalues here.\n",
    "# np_eofs_list = solver.eofs(neofs=modes) # scale by something here?\n",
    "# np_eofscov_list = solver.eofsAsCovariance(neofs=modes)\n",
    "# np_pcs = solver.pcs(npcs=modes)\n",
    "# np_eigs = solver.eigenvalues(neigs=modes) \n",
    "# sum_eigs = solver.eigenvalues().sum()\n",
    "# percent_var = np_eigs.sum() / solver.eigenvalues().sum()\n",
    "# tav = solver.totalAnomalyVariance()\n",
    "# vf = solver.varianceFraction()\n",
    "\n",
    "# # turn the list of eofs for each variable used in the model into SIC_EOFs, and the rest of the eofs.\n",
    "# sic_eofs = xr.DataArray(np_eofs_list[0],\n",
    "#                        coords = [np.arange(0, modes), sic_lat_bins, sic_lon_bins],\n",
    "#                         dims=['mode', 'y', 'x']) * stds[0]\n",
    "# all_vars_eofs = [sic_eofs] # all_vars_eofs is eventually what has all the eofs to be plotted.\n",
    "# for i in range(nvars):\n",
    "#     all_vars_eofs.append(xr.DataArray(np_eofs_list[i + 1],\n",
    "#                        coords = [np.arange(0, modes), vars_lat_bins, vars_lon_bins],\n",
    "#                         dims=['mode', 'y', 'x']) * stds[i + 1])\n",
    "\n",
    "# # for each mode, get the pc timeseries for all the eofs.\n",
    "# pcs = xr.DataArray(np_pcs, coords=[sic_anom.tdim, np.arange(0, modes)],\n",
    "#                   dims=['tdim', 'mode'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
